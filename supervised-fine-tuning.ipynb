{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[],"dockerImageVersionId":31194,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Install dependencies\n!pip install -q transformers datasets accelerate sentencepiece huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:19:20.568644Z","iopub.execute_input":"2025-12-01T02:19:20.568794Z","iopub.status.idle":"2025-12-01T02:19:23.249793Z","shell.execute_reply.started":"2025-12-01T02:19:20.568775Z","shell.execute_reply":"2025-12-01T02:19:23.248789Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -------------------------------\n# 1. Imports\n# -------------------------------\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:19:27.815388Z","iopub.execute_input":"2025-12-01T02:19:27.815607Z","iopub.status.idle":"2025-12-01T02:20:19.569681Z","shell.execute_reply.started":"2025-12-01T02:19:27.815586Z","shell.execute_reply":"2025-12-01T02:20:19.568805Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/torch_xla/__init__.py:258: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n  warnings.warn(\n/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# -------------------------------\n# 2. Load Alpaca dataset\n# -------------------------------\n# Alpaca dataset is hosted on Hugging Face Hub\ndataset = load_dataset(\"tatsu-lab/alpaca\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:20:23.634410Z","iopub.execute_input":"2025-12-01T02:20:23.635040Z","iopub.status.idle":"2025-12-01T02:20:25.815735Z","shell.execute_reply.started":"2025-12-01T02:20:23.635021Z","shell.execute_reply":"2025-12-01T02:20:25.814789Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16004eadd9484faba53673b19fe85d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-a09b74b3ef9c3b(…):   0%|          | 0.00/24.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d77d0f4880a84fe786860e70c095f21c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a469d0939a2d4137b2dd2fc87ce17f87"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Inspect one sample\nprint(dataset[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:20:37.232814Z","iopub.execute_input":"2025-12-01T02:20:37.233043Z","iopub.status.idle":"2025-12-01T02:20:37.236890Z","shell.execute_reply.started":"2025-12-01T02:20:37.233027Z","shell.execute_reply":"2025-12-01T02:20:37.236050Z"}},"outputs":[{"name":"stdout","text":"{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# -------------------------------\n# 3. Preprocess data\n# -------------------------------\nmodel_id = \"EleutherAI/gpt-neo-125M\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\n# Fix: set pad_token to eos_token\ntokenizer.pad_token = tokenizer.eos_token\n\ndef format_example(example):\n    # Combine instruction + input into a single prompt\n    if example.get(\"input\"):\n        prompt = f\"Instruction: {example['instruction']}\\nInput: {example['input']}\\nOutput:\"\n    else:\n        prompt = f\"Instruction: {example['instruction']}\\nOutput:\"\n    return {\"text\": prompt + example[\"output\"]}\n\nformatted_dataset = dataset[\"train\"].map(format_example)\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n\ntokenized_dataset = formatted_dataset.map(tokenize, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:25:05.250452Z","iopub.execute_input":"2025-12-01T02:25:05.250700Z","iopub.status.idle":"2025-12-01T02:25:14.673994Z","shell.execute_reply.started":"2025-12-01T02:25:05.250681Z","shell.execute_reply":"2025-12-01T02:25:14.673200Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/52002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb3782d563e475d81cdf716ac8c75d0"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# -------------------------------\n# 4. Load base model\n# -------------------------------\nmodel = AutoModelForCausalLM.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:26:01.869466Z","iopub.execute_input":"2025-12-01T02:26:01.869738Z","iopub.status.idle":"2025-12-01T02:26:04.879992Z","shell.execute_reply.started":"2025-12-01T02:26:01.869718Z","shell.execute_reply":"2025-12-01T02:26:04.878883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cebac8da576247b1bbd46d32ffaac3cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4254de54312947da8b9569191efaf2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b43aeff99cd24abf977b218ac944d541"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"!pip install -U transformers accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:33:15.989172Z","iopub.execute_input":"2025-12-01T02:33:15.989624Z","iopub.status.idle":"2025-12-01T02:33:25.985073Z","shell.execute_reply.started":"2025-12-01T02:33:15.989589Z","shell.execute_reply":"2025-12-01T02:33:25.983541Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/site-packages (4.57.1)\nCollecting transformers\n  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/site-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/site-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/site-packages (from transformers) (2.3.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/site-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/site-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/site-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/site-packages (from transformers) (0.7.0rc0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/site-packages (from accelerate) (7.1.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/site-packages (from accelerate) (2.8.0+cpu)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6rc0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\nDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\nInstalling collected packages: accelerate, transformers\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\nSuccessfully installed accelerate-1.12.0 transformers-4.57.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# -------------------------------\n# 5. Training setup\n# -------------------------------\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    learning_rate=5e-5,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_steps=500,\n    warmup_steps=100,\n    weight_decay=0.01,\n    optim=\"adamw_torch_xla\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_dataset.select(range(1000)),  # small eval subset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:33:59.036337Z","iopub.execute_input":"2025-12-01T02:33:59.036634Z","iopub.status.idle":"2025-12-01T02:33:59.054118Z","shell.execute_reply.started":"2025-12-01T02:33:59.036613Z","shell.execute_reply":"2025-12-01T02:33:59.052892Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_12/3718424342.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"\n# -------------------------------\n# 6. Train\n# -------------------------------\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:34:03.879271Z","iopub.execute_input":"2025-12-01T02:34:03.879567Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8' max='2439' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   8/2439 00:08 < 59:48, 0.68 it/s, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"#-------------------------------\n# 7. Save model\n# -------------------------------\ntrainer.save_model(\"./alpaca-gptneo-125m\")\ntokenizer.save_pretrained(\"./alpaca-gptneo-125m\")\n\n# -------------------------------\n# 8. Test inference\n# -------------------------------\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"./alpaca-gptneo-125m\", tokenizer=tokenizer)\n\nprint(pipe(\"Instruction: Write a poem about F1 racing\\nOutput:\", max_new_tokens=100)[0][\"generated_text\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}